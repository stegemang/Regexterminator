{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regexterminator script\n",
    "\n",
    "### To do's:\n",
    "- [ ] scrape SO and/or github for common regex solutions\n",
    "- [ ] scrape for common regex problems/data sets to train on\n",
    "- [ ] engineer features\n",
    "   - [ ] checking out text aligning tools from genetics?\n",
    "   - [ ] pre-trained NN layer for parts of text/speech?\n",
    "- [ ] make model work\n",
    "- [ ] make flask app/website\n",
    "- [ ] take in multiple inputs examples\n",
    "- [ ] take in feedback\n",
    "- [ ] run on a cloud server, train massive dataset\n",
    "- [ ] Use reinforcement somehow? reward short answers?\n",
    "\n",
    "\n",
    "### common naming mix-ups\n",
    "start and original, are the sentences/stings in the raw data\n",
    "\n",
    "end and replacement are the sentences/string after the regex is applied\n",
    "\n",
    "sentences are the input/example/sample to emulate what the user might enter. They do not need to be sentences with words, can be numbers, jibberisht, weird strings of characters etc. Hopefully something from a regular language though...\n",
    "\n",
    "## fun times~!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%qtconsole #Initiate console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import difflib\n",
    "import re\n",
    "import pickle # exporting structures for external saves and quick read back into python\n",
    "import string # for counting type of characters in strings\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../\"\n",
    "path = \"/Users/gregorystegeman/Documents/Regexterminator/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO: use stack overflow API to find top regex queries\\nMaybe searh for str.replace in gitHub\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/tagged/regex\n",
    "'''\n",
    "TODO: use stack overflow API to find top regex queries\n",
    "Maybe searh for str.replace in gitHub\n",
    "\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super simple set for easy following though pipeline here:\n",
    "\n",
    "sample_regex_patterns = [r'[a-z]', #lowercase letters\n",
    "                         r'[A-Z]', #uppercase letters\n",
    "                         r'\\s', #whitespace\n",
    "                         r'[^A-Za-z0-9]', #no letters or numbers\n",
    "                         r'[A-Za-z]', #letters any case\n",
    "                         r'[0-9]', #numbers\n",
    "                         r'.$', #last character\n",
    "                         r'^.', #first character\n",
    "                         r'^\\w', #first word\n",
    "                         r'\\w$' #last word            \n",
    "                        ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_regex_patterns = [\n",
    "    r'\\d+',\n",
    "    r'[a-z]',\n",
    "    r'[A-Z]',\n",
    "    r'\\s',\n",
    "    r'[^A-Za-z0-9]',\n",
    "    r'[0-9]',\n",
    "    r'http\\S+',\n",
    "    r'(.*);(.*)',\n",
    "    r'^(\\d{3})-(\\d{3})-(\\d{4})$',\n",
    "    r'^(\\d{3})\\D+(\\d{3})\\D+(\\d{4})\\D+(\\d+)$',\n",
    "    r'([\\w0-9_]+)',\n",
    "    r'^.+',\n",
    "    r'([^:：]+)[:：]?\\s*',\n",
    "    r'\\d+/\\d+/\\d+',\n",
    "    r'\\.[0]*',\n",
    "    r'[,;_]',\n",
    "    r'[\\w\\d]{1,20}[\\w]{1,20}[\\w]{1,5}',\n",
    "    r'(.+) \\1',\n",
    "    r'http\\S+\\s',\n",
    "    r'RT|cc',\n",
    "    r'[^A-Za-z0-9]+',\n",
    "    r'\\w',\n",
    "    r'\\n|\\r',\n",
    "    r'^([A-Za-z]\\d[A-Za-z][-]?\\d[A-Za-z]\\d)',\n",
    "    r'[:]{1}[-~+o]?[)&gt;]+',\n",
    "    r'(\\:\\w+\\:|\\<[\\/\\\\]?3|[\\(\\)\\\\\\D|\\*\\$][\\-\\^]?[\\:\\;\\=]|[\\:\\;\\=B8][\\-\\^]?[3DOPp\\@\\$\\*\\\\\\)\\(\\/\\|])(?=\\s|[\\!\\.\\?]|$)',\n",
    "    r'<[^>]*>',\n",
    "    r'\\xA9',\n",
    "    r'(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)',\n",
    "    r'@\\S+',\n",
    "    r'#\\S+',\n",
    "    r'^\\d+',\n",
    "    r'^[a-z]',\n",
    "    r'^[A-Z]',\n",
    "    r'^\\s',\n",
    "    r\"^[^A-Za-z0-9]\",\n",
    "    r'^[0-9]',\n",
    "    \n",
    "                        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary to reference regex pattern classes\n",
    "regex_dict = {}\n",
    "for i in sample_regex_patterns:\n",
    "    regex_dict['c_'+ str(sample_regex_patterns.index(i))] = i\n",
    "    \n",
    "#Save regex_dict in pickle; move to flask app later\n",
    "pickle.dump(regex_dict, open('regex_dict.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape/acquire sentences from: \n",
    "- [ ] twitter\n",
    "- [ ] wikipedia\n",
    "- [ ] yelp reviews (Ming He)\n",
    "- [ ] steam game reviews\n",
    "- [ ] copy from other fellows\n",
    "- [ ] Excel help forums\n",
    "- [ ] amazon reviews (Patrick Lestrange)\n",
    "- [ ] Medium (Kim S)\n",
    "- [ ] StackOverFlow comment and questions\n",
    "- [ ] BGG (Pam M)\n",
    "\n",
    "Stuff to include\n",
    "- numbers\n",
    "- phone numbers\n",
    "- postal codes\n",
    "- email address\n",
    "- code segments\n",
    "- dates of different formats\n",
    "- IP addresses\n",
    "- addresses\n",
    "- multi line?\n",
    "- non standard characters?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller test dataset\n",
    "start_sentences = pd.read_csv(path + 'garbage_data.csv')\n",
    "\n",
    "start_sentences = start_sentences[\"garbage data\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloaded random dataset from https://www.figure-eight.com/data-for-everyone/\n",
    "df = pd.read_csv(path + '1377191648_sentiment_nuclear_power.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "#Only really care about tweet_text column\n",
    "start_sentences = start_sentences + df.tweet_text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in 100 sample tweets from twitter100k dataset:\n",
    "tweetlines = open(path + \"tweet_samples.txt\").read().splitlines()\n",
    "\n",
    "start_sentences = start_sentences + tweetlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMS messages from:\n",
    "# https://github.com/kite1988/nus-sms-corpus\n",
    "import json\n",
    "with open(path + \"smsCorpus_en_2015.03.09_all.json\") as f:\n",
    "    sms_data = json.load(f)\n",
    "\n",
    "sms = sms_data['smsCorpus']\n",
    "sms = sms.get('message')\n",
    "\n",
    "sms_texts = []\n",
    "for message in sms:\n",
    "    sms_texts.append(message['text']['$'])\n",
    "\n",
    "# Maybe random later, for now keep it the same:    \n",
    "sms_subset = sms_texts[0:1000]\n",
    "\n",
    "start_sentences = start_sentences + sms_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef priceGen():\\n    p=list('0000000000')\\n    return '$' p[3:6] + '-' + p[6:]\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate some fake number data and then mess it up\n",
    "\n",
    "# phone numbers\n",
    "\n",
    "'''\n",
    "754-3010 Local\n",
    "(541) 754-3010 Domestic\n",
    "+1-541-754-3010 International\n",
    "1-541-754-3010 Dialed in the US\n",
    "001-541-754-3010 Dialed from Germany\n",
    "191 541 754 3010 Dialed from France\n",
    "636-48018 Local\n",
    "(089) / 636-48018 Domestic\n",
    "+49-89-636-48018 International\n",
    "19-49-89-636-48018 Dialed from France\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def phn():\n",
    "    p=list('0000000000')\n",
    "    p[0] = str(random.randint(1,9))\n",
    "    for i in [1,2,6,7,8]:\n",
    "        p[i] = str(random.randint(0,9))\n",
    "    for i in [3,4]:\n",
    "        p[i] = str(random.randint(0,8))\n",
    "    if p[3]==p[4]==0:\n",
    "        p[5]=str(random.randint(1,8))\n",
    "    else:\n",
    "        p[5]=str(random.randint(0,8))\n",
    "    n = range(10)\n",
    "    if p[6]==p[7]==p[8]:\n",
    "        n = (i for i in n if i!=p[6])\n",
    "    p[9] = str(random.choice(n))\n",
    "    p = ''.join(p)\n",
    "    return p[:3] + '-' + p[3:6] + '-' + p[6:]\n",
    "\n",
    "def phnBrackets():\n",
    "    p=list('0000000000')\n",
    "    p[0] = str(random.randint(1,9))\n",
    "    for i in [1,2,6,7,8]:\n",
    "        p[i] = str(random.randint(0,9))\n",
    "    for i in [3,4]:\n",
    "        p[i] = str(random.randint(0,8))\n",
    "    if p[3]==p[4]==0:\n",
    "        p[5]=str(random.randint(1,8))\n",
    "    else:\n",
    "        p[5]=str(random.randint(0,8))\n",
    "    n = range(10)\n",
    "    if p[6]==p[7]==p[8]:\n",
    "        n = (i for i in n if i!=p[6])\n",
    "    p[9] = str(random.choice(n))\n",
    "    p = ''.join(p)\n",
    "    return '(' + p[:3] + ') ' + p[3:6] + '-' + p[6:]\n",
    "\n",
    "def localPhn():\n",
    "    p=list('0000000000')\n",
    "    p[0] = str(random.randint(1,9))\n",
    "    for i in [1,2,6,7,8]:\n",
    "        p[i] = str(random.randint(0,9))\n",
    "    for i in [3,4]:\n",
    "        p[i] = str(random.randint(0,8))\n",
    "    if p[3]==p[4]==0:\n",
    "        p[5]=str(random.randint(1,8))\n",
    "    else:\n",
    "        p[5]=str(random.randint(0,8))\n",
    "    n = range(10)\n",
    "    if p[6]==p[7]==p[8]:\n",
    "        n = (i for i in n if i!=p[6])\n",
    "    p[9] = str(random.choice(n))\n",
    "    p = ''.join(p)\n",
    "    return p[3:6] + '-' + p[6:]\n",
    "\n",
    "# zipcodes\n",
    "\n",
    "# prices\n",
    "\"\"\"\n",
    "def priceGen():\n",
    "    p=list('0000000000')\n",
    "    return '$' p[3:6] + '-' + p[6:]\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add to sentences a sentence that contains all alphanumeric characters that we ever expect to encounter\n",
    "start_sentences.append('The quick brown fox jumped over the lazy dog')\n",
    "start_sentences.append('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuv')\n",
    "start_sentences.append('`1234567890-=~!@#$%^&*()_+[]\\{}|;\\':\\\",./<>?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force all things in list to be strings\n",
    "\n",
    "start_sentences = [str(i) for i in start_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Feature Engineering\n",
    "\n",
    "## 2.0 Generate training data with unmodified/start sentence and a processed replacement/end sentence.\n",
    "\n",
    "No regular expressions in feature creation!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a new data frame that captures both the regex and also the \n",
    "sentence transformation\n",
    "'''\n",
    "start_regexed_end = pd.DataFrame() #Initialize empty data frame\n",
    "\n",
    "for regex in sample_regex_patterns:\n",
    "    for sentence in start_sentences:\n",
    "        r = re.compile(regex)\n",
    "        d = {\n",
    "            'sentence': sentence,\n",
    "            'regex': regex,\n",
    "            'replacement': re.sub(r,'',sentence)\n",
    "        }\n",
    "        \n",
    "        start_regexed_end = start_regexed_end.append(d, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save/pickle it, that takes a long time to run:\n",
    "\n",
    "pickle.dump(start_regexed_end, open('start_regexed_end.pickle', 'wb'))\n",
    "\n",
    "start_regexed_end = pickle.load(open('start_regexed_end.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>replacement</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[0-9]</th>\n",
       "      <td>972</td>\n",
       "      <td>972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[A-Z]</th>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[A-Za-z]</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[^A-Za-z0-9]</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[a-z]</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\s</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\w$</th>\n",
       "      <td>1117</td>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>^\\w</th>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              replacement  sentence\n",
       "regex                              \n",
       "[0-9]                 972       972\n",
       "[A-Z]                 205       205\n",
       "[A-Za-z]                4         4\n",
       "[^A-Za-z0-9]           13        13\n",
       "[a-z]                   8         8\n",
       "\\s                     53        53\n",
       "\\w$                  1117      1117\n",
       "^\\w                    89        89"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How much was changed/affected by regex's?\n",
    "\n",
    "'''\n",
    "1. Find if difference between start_regexed_end.sentence & start_regexed_end.replacement\n",
    "2. Group by 'regex'\n",
    "'''\n",
    "\n",
    "#print(start_regexed_end.groupby(['regex']).sum(start_regexed_end['sentence'] != start_regexed_end['replacement']))      \n",
    "start_regexed_end[start_regexed_end.sentence == start_regexed_end.replacement].groupby('regex').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also wondering which regex give the same result from each processing.\n",
    "# Which are redundant or overlapping all the time or part of the time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regex</th>\n",
       "      <th>replacement</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a-z]</td>\n",
       "      <td>! BLAH!!!</td>\n",
       "      <td>blah blah! BLAH!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[a-z]</td>\n",
       "      <td>42433443</td>\n",
       "      <td>42hj43hj34hj43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[a-z]</td>\n",
       "      <td>4.243.;;33;</td>\n",
       "      <td>4.243.gf;gfsd;3g3g;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[a-z]</td>\n",
       "      <td>.2 3.</td>\n",
       "      <td>fdsa.2l fe3f. rlfkk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[a-z]</td>\n",
       "      <td>.!!!</td>\n",
       "      <td>derp derp doop.!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   regex  replacement             sentence\n",
       "0  [a-z]    ! BLAH!!!   blah blah! BLAH!!!\n",
       "1  [a-z]     42433443       42hj43hj34hj43\n",
       "2  [a-z]  4.243.;;33;  4.243.gf;gfsd;3g3g;\n",
       "3  [a-z]       .2 3.   fdsa.2l fe3f. rlfkk\n",
       "4  [a-z]         .!!!   derp derp doop.!!!"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_regexed_end.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Find differences between `start` and `end` sentence inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charCounts(column, colname):\n",
    "    \"\"\"\n",
    "    Counts the different type of characters in a string\n",
    "    \n",
    "    @param column: to apply lambda function to\n",
    "    @param colname: what the unique columns should be named\n",
    "    \n",
    "    \"\"\"\n",
    "    # This is really ugly, something I could do in R very easily:\n",
    "    count = lambda l1, l2: len(list(filter(lambda c: c in l2, l1)))\n",
    "\n",
    "    out = column.apply(\n",
    "    lambda s: pd.Series(\n",
    "        {colname+'punct': count(s,set(string.punctuation)),\n",
    "         colname+'letters': count(s,set(string.ascii_letters)),\n",
    "         colname+'digits': count(s,set(string.digits)),\n",
    "         colname+'lower': count(s,set(string.ascii_lowercase)),\n",
    "         colname+'upper': count(s,set(string.ascii_uppercase)),\n",
    "         colname+'whitespace': count(s,set(string.whitespace)),\n",
    "         colname+'words': len(s.split()),\n",
    "        }))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_counts = charCounts(start_regexed_end['sentence'], 'start_n_')\n",
    "end_counts = charCounts(start_regexed_end['replacement'], 'end_n_')\n",
    "\n",
    "type_counts = pd.concat([start_regexed_end, start_counts, end_counts], axis= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef countComparison(df)\\n    start_counts = charCounts(df['sentence'], 'start_n_')\\n    end_counts = charCounts(df['replacement'], 'end_n_')\\n\\n\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each column with the same suffix, find the \"end\" prefix column and subrtract it from the \"start\" prefic column.\n",
    "'''\n",
    "def countComparison(df)\n",
    "    start_counts = charCounts(df['sentence'], 'start_n_')\n",
    "    end_counts = charCounts(df['replacement'], 'end_n_')\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regex</th>\n",
       "      <th>replacement</th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_n_punct</th>\n",
       "      <th>start_n_letters</th>\n",
       "      <th>start_n_digits</th>\n",
       "      <th>start_n_lower</th>\n",
       "      <th>start_n_upper</th>\n",
       "      <th>start_n_whitespace</th>\n",
       "      <th>start_n_words</th>\n",
       "      <th>end_n_punct</th>\n",
       "      <th>end_n_letters</th>\n",
       "      <th>end_n_digits</th>\n",
       "      <th>end_n_lower</th>\n",
       "      <th>end_n_upper</th>\n",
       "      <th>end_n_whitespace</th>\n",
       "      <th>end_n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a-z]</td>\n",
       "      <td>! BLAH!!!</td>\n",
       "      <td>blah blah! BLAH!!!</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[a-z]</td>\n",
       "      <td>42433443</td>\n",
       "      <td>42hj43hj34hj43</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[a-z]</td>\n",
       "      <td>4.243.;;33;</td>\n",
       "      <td>4.243.gf;gfsd;3g3g;</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[a-z]</td>\n",
       "      <td>.2 3.</td>\n",
       "      <td>fdsa.2l fe3f. rlfkk</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[a-z]</td>\n",
       "      <td>.!!!</td>\n",
       "      <td>derp derp doop.!!!</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   regex  replacement             sentence  start_n_punct  start_n_letters  \\\n",
       "0  [a-z]    ! BLAH!!!   blah blah! BLAH!!!              4               12   \n",
       "1  [a-z]     42433443       42hj43hj34hj43              0                6   \n",
       "2  [a-z]  4.243.;;33;  4.243.gf;gfsd;3g3g;              5                8   \n",
       "3  [a-z]       .2 3.   fdsa.2l fe3f. rlfkk              2               13   \n",
       "4  [a-z]         .!!!   derp derp doop.!!!              4               12   \n",
       "\n",
       "   start_n_digits  start_n_lower  start_n_upper  start_n_whitespace  \\\n",
       "0               0              8              4                   2   \n",
       "1               8              6              0                   0   \n",
       "2               6              8              0                   0   \n",
       "3               2             13              0                   2   \n",
       "4               0             12              0                   2   \n",
       "\n",
       "   start_n_words  end_n_punct  end_n_letters  end_n_digits  end_n_lower  \\\n",
       "0              3            4              4             0            0   \n",
       "1              1            0              0             8            0   \n",
       "2              1            5              0             6            0   \n",
       "3              3            2              0             2            0   \n",
       "4              3            4              0             0            0   \n",
       "\n",
       "   end_n_upper  end_n_whitespace  end_n_words  \n",
       "0            4                 2            2  \n",
       "1            0                 0            1  \n",
       "2            0                 0            1  \n",
       "3            0                 2            2  \n",
       "4            0                 2            1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More feature engineering\n",
    "\n",
    "sequences of similar character types (letter, number, white space and punctuation)\n",
    "\n",
    "beginning and ends of sentences\n",
    "\n",
    "word boundaries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def endChecks(dataf, start_col, end_col, regex = False):\n",
    "    \"\"\"\n",
    "    Checks if end words and characters are the same between two strings (from columns)\n",
    "    \n",
    "    @param dataf: pandas dataframe.\n",
    "    @param start_col: initial string\n",
    "    @param end_col: modified string to compare to\n",
    "    @param regex: include regex in new table for indexing.\n",
    "    \n",
    "    @return: returns dataframe with start column and regex for indexing, and four new columns of features\n",
    "    \"\"\"\n",
    "    out = pd.DataFrame()\n",
    "    for index, row in dataf.iterrows():\n",
    "        tmp = {\n",
    "            start_col: row[start_col],\n",
    "            'regex': row['regex'] if regex else '',\n",
    "            'first_word_same': row[start_col].split()[0] == row[end_col].split()[0] if len(row[end_col].split())>0 else False,\n",
    "            'first_char_same': row[start_col][0] == row[end_col][0] if len(row[end_col].split())>0 else False,\n",
    "            'last_word_same': row[start_col].split()[-1] == row[end_col].split()[-1] if len(row[end_col].split())>0 else False,\n",
    "            'last_char_same': row[start_col][-1] == row[end_col][-1] if len(row[end_col].split())>0 else False,\n",
    "        }\n",
    "        out = out.append(tmp, ignore_index=True)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_ends = endChecks(start_regexed_end, 'sentence','replacement', regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more features?\n",
    "\n",
    "position of difference\n",
    "\n",
    "difference at beginning or end?\n",
    "\n",
    "aligned difference?\n",
    "\n",
    "how many words remain same?\n",
    "\n",
    "longest run of digits, letters, etc.\n",
    "\n",
    "proportion of characters of a class removed?\n",
    "\n",
    "Are @'s removed?\n",
    "Are #'s removed?\n",
    "Are -'s removed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Test/Train data splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Feature Variables (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features I want to work with and drop the label stuff\n",
    "\n",
    "#list(dummies.columns.values)\n",
    "list(type_counts.columns.values)\n",
    "\n",
    "features_combo = pd.merge(type_counts, string_ends, on=[\"sentence\",\"regex\"])\n",
    "\n",
    "list(features_combo.columns.values)\n",
    "\n",
    "X = features_combo.drop(['sentence', 'regex', 'replacement'], axis=1).values #Remove everything but the feature variables\n",
    "X = features_combo.drop(['sentence', 'regex', 'replacement'], axis=1) #Remove everything but the feature variables\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regex</th>\n",
       "      <th>replacement</th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_n_punct</th>\n",
       "      <th>start_n_letters</th>\n",
       "      <th>start_n_digits</th>\n",
       "      <th>start_n_lower</th>\n",
       "      <th>start_n_upper</th>\n",
       "      <th>start_n_whitespace</th>\n",
       "      <th>start_n_words</th>\n",
       "      <th>...</th>\n",
       "      <th>end_n_letters</th>\n",
       "      <th>end_n_digits</th>\n",
       "      <th>end_n_lower</th>\n",
       "      <th>end_n_upper</th>\n",
       "      <th>end_n_whitespace</th>\n",
       "      <th>end_n_words</th>\n",
       "      <th>first_char_same</th>\n",
       "      <th>first_word_same</th>\n",
       "      <th>last_char_same</th>\n",
       "      <th>last_word_same</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a-z]</td>\n",
       "      <td>! BLAH!!!</td>\n",
       "      <td>blah blah! BLAH!!!</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[a-z]</td>\n",
       "      <td>42433443</td>\n",
       "      <td>42hj43hj34hj43</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[a-z]</td>\n",
       "      <td>4.243.;;33;</td>\n",
       "      <td>4.243.gf;gfsd;3g3g;</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[a-z]</td>\n",
       "      <td>.2 3.</td>\n",
       "      <td>fdsa.2l fe3f. rlfkk</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[a-z]</td>\n",
       "      <td>.!!!</td>\n",
       "      <td>derp derp doop.!!!</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   regex  replacement             sentence  start_n_punct  start_n_letters  \\\n",
       "0  [a-z]    ! BLAH!!!   blah blah! BLAH!!!              4               12   \n",
       "1  [a-z]     42433443       42hj43hj34hj43              0                6   \n",
       "2  [a-z]  4.243.;;33;  4.243.gf;gfsd;3g3g;              5                8   \n",
       "3  [a-z]       .2 3.   fdsa.2l fe3f. rlfkk              2               13   \n",
       "4  [a-z]         .!!!   derp derp doop.!!!              4               12   \n",
       "\n",
       "   start_n_digits  start_n_lower  start_n_upper  start_n_whitespace  \\\n",
       "0               0              8              4                   2   \n",
       "1               8              6              0                   0   \n",
       "2               6              8              0                   0   \n",
       "3               2             13              0                   2   \n",
       "4               0             12              0                   2   \n",
       "\n",
       "   start_n_words       ...        end_n_letters  end_n_digits  end_n_lower  \\\n",
       "0              3       ...                    4             0            0   \n",
       "1              1       ...                    0             8            0   \n",
       "2              1       ...                    0             6            0   \n",
       "3              3       ...                    0             2            0   \n",
       "4              3       ...                    0             0            0   \n",
       "\n",
       "   end_n_upper  end_n_whitespace  end_n_words  first_char_same  \\\n",
       "0            4                 2            2              0.0   \n",
       "1            0                 0            1              1.0   \n",
       "2            0                 0            1              1.0   \n",
       "3            0                 2            2              0.0   \n",
       "4            0                 2            1              0.0   \n",
       "\n",
       "   first_word_same  last_char_same  last_word_same  \n",
       "0              0.0             1.0             1.0  \n",
       "1              0.0             1.0             0.0  \n",
       "2              0.0             1.0             0.0  \n",
       "3              0.0             0.0             0.0  \n",
       "4              0.0             1.0             0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_combo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Target Variable (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Convert regex labels to numeric value depending on where it occurs in the sample_regex_patterns list\n",
    "'''\n",
    "y = ['c_'+str(sample_regex_patterns.index(i)) for i in features_combo.regex]\n",
    "\n",
    "#Find the value (features_combo.regex) for the key in regex_dict\n",
    "def findRegexClass(dict_to_search, dict_value):\n",
    "    \"\"\"\n",
    "    Function to find the key \n",
    "    \n",
    "    @param dict_to_search: The dict to search for the key for the given value\n",
    "    @param dict_value: The value to find the corresponding key for\n",
    "    \n",
    "    @return: the key\n",
    "    \"\"\"\n",
    "    return [key for key, value in dict_to_search.items() if dict_value == value][0]\n",
    "\n",
    "# For each regex in dummies.regex, find the corresponding class/key to form the y-label\n",
    "y = [findRegexClass(regex_dict, i) for i in features_combo.regex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Test/Train data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kdnuggets.com/2017/03/simple-xgboost-tutorial-iris-dataset.html\n",
    "'''import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 20  # the number of training iterations\n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Model Fitting & Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.6966292134831461\n",
      "test score: 0.7032385988103106\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter Tuning\n",
    "\"\"\"\n",
    "Looks like Logistic and XGBoost are performing the best. \n",
    "Tune the top 2 models and compare\n",
    "\"\"\"\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    XGBClassifier(),\n",
    "    {\n",
    "        'max_depth':(4,30),#maximum depth of a tree\n",
    "        'eta': (0,1),#learning rate\n",
    "        'min_child_weight': (0,10), #minimum sum of instance weight ndeed in a child\n",
    "        'max_delta_step': (0,10) #Step of each leaf output.\n",
    "    },\n",
    "    n_iter = 21\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0, 'max_delta_step': 1, 'max_depth': 4, 'min_child_weight': 10}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get the best parameters for the XGBoost\n",
    "{'eta': 0, 'max_delta_step': 1, 'max_depth': 4, 'min_child_weight': 10}\n",
    "\"\"\"\n",
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['start_n_punct', 'start_n_letters', 'start_n_digits', 'start_n_lower', 'start_n_upper', 'start_n_whitespace', 'start_n_words', 'end_n_punct', 'end_n_letters', 'end_n_digits', 'end_n_lower', 'end_n_upper', 'end_n_whitespace', 'end_n_words', 'first_char_same', 'first_word_same', 'last_char_same', 'last_word_same'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17']\nexpected start_n_upper, end_n_upper, end_n_digits, end_n_lower, end_n_punct, start_n_digits, end_n_whitespace, last_char_same, start_n_whitespace, first_word_same, start_n_punct, start_n_letters, start_n_lower, last_word_same, start_n_words, end_n_letters, first_char_same, end_n_words in input data\ntraining data did not have the following fields: f6, f4, f8, f16, f11, f12, f13, f5, f15, f9, f0, f17, f2, f10, f7, f3, f14, f1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-974a744c7162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \"\"\"\n\u001b[1;32m    490\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_estimator_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    757\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                                                  validate_features=validate_features)\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1541\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['start_n_punct', 'start_n_letters', 'start_n_digits', 'start_n_lower', 'start_n_upper', 'start_n_whitespace', 'start_n_words', 'end_n_punct', 'end_n_letters', 'end_n_digits', 'end_n_lower', 'end_n_upper', 'end_n_whitespace', 'end_n_words', 'first_char_same', 'first_word_same', 'last_char_same', 'last_word_same'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17']\nexpected start_n_upper, end_n_upper, end_n_digits, end_n_lower, end_n_punct, start_n_digits, end_n_whitespace, last_char_same, start_n_whitespace, first_word_same, start_n_punct, start_n_letters, start_n_lower, last_word_same, start_n_words, end_n_letters, first_char_same, end_n_words in input data\ntraining data did not have the following fields: f6, f4, f8, f16, f11, f12, f13, f5, f15, f9, f0, f17, f2, f10, f7, f3, f14, f1"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Can predict features here\n",
    "\"\"\"\n",
    "opt.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.7293456708526107\n",
      "test score: 0.7376074025115664\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter Tuning\n",
    "\"\"\"\n",
    "Optimize for the logistic regression\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "opt_logistic = BayesSearchCV(\n",
    "    LogisticRegression(),\n",
    "    {\n",
    "        'C':(0.1,1),#maximum depth of a tree\n",
    "    },\n",
    "    n_iter = 21\n",
    ")\n",
    "\n",
    "opt_logistic.fit(X_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt_logistic.best_score_)\n",
    "print(\"test score: %s\" % opt_logistic.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Can predict features here\n",
    "\"\"\"\n",
    "opt_logistic.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train, sample_weight=None, check_input=True)\n",
    "\n",
    "cross_val_score(clf, X_train, y_train, cv=10)\n",
    "#cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "# grid search cv or something to find optimal parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Boosted Gradient Tree?\n",
    "\n",
    "XG Boost?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model to training data\n",
    "xgb_model = XGBClassifier(nthread = -1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgbcrossval = cross_val_score(xgb_model, X_train, y_train, cv=10)\n",
    "\n",
    "print(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
    "\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# load dataset\n",
    "#url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "#names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "#dataframe = pandas.read_csv(url, names=names)\n",
    "#array = dataframe.values\n",
    "X = X_train\n",
    "Y = y_train\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('RF', DecisionTreeClassifier()))\n",
    "models.append(('XGBoost', XGBClassifier()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\tcv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEVCAYAAAAM3jVmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFn9JREFUeJzt3X+0XWV95/H3B2K0HVSSJlaFQFCDozSK9Zbx96+K0g4rjGs6kEw6BpzKWAdtdeqIHZci1o5Tax1/0OmirpZRGxAZhVh1AktTf1DQ3EwxkDBoiKPE+COSUExBCPidP86OHi43954b7s25N8/7tdZe2fvZz977eU7O+pznPPuce1JVSJLacMSwGyBJOnQMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6mpIklyT5oxk69+okV0+w/0VJdszEtee6JH+Y5MPDbodmP0Nf40ryd0n2JHn4obpmVf1NVb2srw2V5EmH6vrpeX2Sm5L8U5IdST6RZPmhasPBqqo/rqrfGXY7NPsZ+nqQJEuB5wMFrDhE15x3KK4zifcDvwe8HlgInAhcCfzLYTZqMrPksdMcYehrPK8ErgcuAdZMVDHJf07yvSQ7k/xO/+g8yaOTfCTJriTfTvLWJEd0+85Ocm2S9yXZDVzQlX2l2/+l7hJfT7I3yVl91/xPSX7YXfecvvJLkvx5ks91x1yb5LFJ/nv3ruX/JnnGAfqxDPiPwKqq+kJV3VNVd3XvPt49xf7ckWR7kud05bd17V0zpq1/keSaJD9O8sUkx/ftf3933J1JNiV5ft++C5JckeRjSe4Ezu7KPtbtf0S37/auLRuT/HK37/FJ1iXZnWRbklePOe/lXR9/nGRLkpGJ/v819xj6Gs8rgb/plpfvD4yxkpwGvBF4KfAk4IVjqnwQeDTwhG7fK4Fz+vb/C2A78BjgXf0HVtULutWnV9VRVfXxbvux3TmPAf49cFGSBX2Hngm8FVgE3ANcB/yfbvsK4M8O0OdfB3ZU1dcOsH/Q/mwGfglYC1wG/Bq9x+a3gQ8lOaqv/mrgnV3bbqD3eO+3ETiZ3juOtcAnkjyib/8ZXX+OHnMc9F6oHw0s6dryGuDubt+lwA7g8cBvAX+c5Nf7jl3RtftoYB3woQkeD81Bhr4eIMnzgOOBy6tqE3Ar8G8PUP1M4K+raktV3QW8o+88RwJnAW+pqh9X1f8D3gv8u77jd1bVB6vqvqq6m8HsAy6sqn1V9VlgL/Dkvv2fqqpNVfUT4FPAT6rqI1V1P/BxYNyRPr1w/N6BLjpgf75VVX/dd60lXVvvqaqrgXvpvQDs95mq+lJV3QP8F+DZSZYAVNXHqur27rF5L/DwMf28rqqurKqfjvPY7ev686Squr97PO7szv084M1V9ZOqugH48Jg+fKWqPtv14aPA0w/0mGhuMvQ11hrg6qr6Ube9lgNP8TweuK1vu399ETAf+HZf2bfpjdDHqz+o26vqvr7tu4D+0fMP+tbvHme7v+4Dzgs8boLrDtKfsdeiqia6/s/6X1V7gd30HtP9U1g3J/nHJHfQG7kvGu/YcXwUWA9c1k27/UmSh3Xn3l1VP56gD9/vW78LeIT3DA4vhr5+Jskv0Bu9vzDJ95N8H3gD8PQk4434vgcc27e9pG/9R/RGnMf3lR0HfLdvezb9idfPA8dOMIc9SH+m6mePVzftsxDY2c3fv5ne/8WCqjoa+Ecgfcce8LHr3gW9o6qeCjwHOJ3eVNROYGGSR05jHzTHGPrq96+A+4Gn0ptPPhl4CvBleqEx1uXAOUmekuQXgbft39FND1wOvCvJI7ublG8EPjaF9vyA3vz5jKuqbwJ/Dlya3vcB5nc3RFcmOX+a+jPWbyZ5XpL59Ob2v1pVtwGPBO4DdgHzkrwNeNSgJ03y4iTLuympO+m9WN3fnfvvgf/a9e1p9O6LjL0noMOYoa9+a+jN0X+nqr6/f6F3M2/12Lf5VfU54APABmAbvZum0LuBCvA64J/o3az9Cr2por+aQnsuAP5n9wmUMw+yT1Pxenp9vQi4g979jFcAn+72P9T+jLUWeDu9aZ1n0ruxC72pmc8B36A3/fITpjYV9lh6N3nvBG4GvsjPX5xWAUvpjfo/Bby9qq55CH3QHBN/REXTJclTgJuAh4+Zd9cYSS6h92mhtw67LWqLI309JEle0U2FLAD+G/BpA1+avQx9PVT/gd7c86307gf87nCbI2kiTu9IUkMc6UtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhsy6X7lftGhRLV26dNjNkKQ5ZdOmTT+qqsWT1Zt1ob906VJGR0eH3QxJmlOSfHuQek7vSFJDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhoy676cJenwkuSgjquqaW6JwJG+pGmycOFCkjxoOVjjnWvhwoXT2OI2OdKXNC12v/5+4FEzfJX7Z/j8hz9DX9K0yDvunPFrLFiwgN0XzPhlDmtO70iaFlU18LJ27VpOOukkjjjiCE466STWrl070HG7d+8edjfnPEf6kg6pSy+9lDVr1rBv3z4AtmzZwpo1awBYtWrVMJvWBEf6kg6pc845h3379rFixQp27drFihUr2LdvH+ecc86wm9YEQ1/SIXXPPfdw+umnc9VVV7Fo0SKuuuoqTj/9dO65555hN60Jhr6kQ+5Vr3rVhNuaOYa+pENu9erVbNiwgX379rFhwwZWr1497CY1wxu5kg6p5cuXc+ONN7JixQr27t3LUUcdxd13383y5cuH3bQmONKXdEht3ryZ5cuXs3fvXgD27t3L8uXL2bx585Bb1gZH+pIOOQN+eBzpS1JDDH1JashAoZ/ktCS3JNmW5Pxx9r8vyQ3d8o0kd3TlJye5LsmWJJuTnDXdHZAkDW7SOf0kRwIXAacCO4CNSdZV1db9darqDX31Xwc8o9u8C3hlVX0zyeOBTUnWV9Ud09kJSdJgBhnpnwJsq6rtVXUvcBlwxgT1VwGXAlTVN6rqm936TuCHwOKH1mRJ0sEaJPSPAW7r297RlT1IkuOBE4AvjLPvFGA+cOvUmylJmg6DhP54P31zoN8xWwlcUVUP+KWDJI8DPgqcU1U/fdAFknOTjCYZ3bVr1wBNkiQdjEFCfwewpG/7WGDnAequpJva2S/Jo4DPAG+tquvHO6iqLq6qkaoaWbzY2R9JmimDhP5GYFmSE5LMpxfs68ZWSvJkYAFwXV/ZfOBTwEeq6hPT02RJ0sGaNPSr6j7gPGA9cDNweVVtSXJhkhV9VVcBl9UDf8L+TOAFwNl9H+k8eRrbL0magjwwo4dvZGSkRkdHh90MSZpTkmyqqpHJ6vmNXElqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGjJQ6Cc5LcktSbYlOX+c/e9LckO3fCPJHX371iT5Zresmc7GS5KmZt5kFZIcCVwEnArsADYmWVdVW/fXqao39NV/HfCMbn0h8HZgBChgU3fsnmnthSRpIIOM9E8BtlXV9qq6F7gMOGOC+quAS7v1lwPXVNXuLuivAU57KA2WJB28QUL/GOC2vu0dXdmDJDkeOAH4wlSPlSTNvEFCP+OU1QHqrgSuqKr7p3JsknOTjCYZ3bVr1wBNkiQdjEFCfwewpG/7WGDnAequ5OdTOwMfW1UXV9VIVY0sXrx4gCZJkg7GIKG/EViW5IQk8+kF+7qxlZI8GVgAXNdXvB54WZIFSRYAL+vKJElDMOmnd6rqviTn0QvrI4G/qqotSS4ERqtq/wvAKuCyqqq+Y3cneSe9Fw6AC6tq9/R2QZI0qPRl9KwwMjJSo6Ojw26GJM0pSTZV1chk9fxGriQ1ZNLpHc0NyXgflJrYbHuXJ2nmGfqHiQMFeBLDXdLPOL0zxyxcuJAkAy/AlOonYeHChUPupaSZ4kh/jtmzZ8+Mj9wPZqpI0tzgSF+SGmLoS1JDDH1JaoihL0kN8UbuHFNvfxRc8OiZv4akw5KhP8fkHXcekk/v1AUzeglJQ+L0jiQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGjJQ6Cc5LcktSbYlOf8Adc5MsjXJliRr+8r/pCu7OckHkmS6Gi9Jmpp5k1VIciRwEXAqsAPYmGRdVW3tq7MMeAvw3Krak+QxXflzgOcCT+uqfgV4IfB309kJSdJgBhnpnwJsq6rtVXUvcBlwxpg6rwYuqqo9AFX1w668gEcA84GHAw8DfjAdDZckTd0goX8McFvf9o6urN+JwIlJrk1yfZLTAKrqOmAD8L1uWV9VN4+9QJJzk4wmGd21a9fB9EOSNIBBQn+8Ofgasz0PWAa8CFgFfDjJ0UmeBDwFOJbeC8VLkrzgQSeruriqRqpqZPHixVNpvyRpCgYJ/R3Akr7tY4Gd49S5qqr2VdW3gFvovQi8Ari+qvZW1V7gc8CzHnqzJUkHY5DQ3wgsS3JCkvnASmDdmDpXAi8GSLKI3nTPduA7wAuTzEvyMHo3cR80vSNJOjQmDf2qug84D1hPL7Avr6otSS5MsqKrth64PclWenP4b6qq24ErgFuBG4GvA1+vqk/PQD8kSQNI1djp+eEaGRmp0dHRYTdj1krCTP+fHYprSJpeSTZV1chk9fxGriQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDRko9JOcluSWJNuSnH+AOmcm2ZpkS5K1feXHJbk6yc3d/qXT03RJ0lTNm6xCkiOBi4BTgR3AxiTrqmprX51lwFuA51bVniSP6TvFR4B3VdU1SY4CfjqtPZAkDWyQkf4pwLaq2l5V9wKXAWeMqfNq4KKq2gNQVT8ESPJUYF5VXdOV762qu6at9ZKkKRkk9I8Bbuvb3tGV9TsRODHJtUmuT3JaX/kdST6Z5B+SvKd75/AASc5NMppkdNeuXQfTD0nSAAYJ/YxTVmO25wHLgBcBq4APJzm6K38+8AfArwFPAM5+0MmqLq6qkaoaWbx48cCNlyRNzSChvwNY0rd9LLBznDpXVdW+qvoWcAu9F4EdwD90U0P3AVcCv/rQmy1JOhiDhP5GYFmSE5LMB1YC68bUuRJ4MUCSRfSmdbZ3xy5Isn/4/hJgK5KkoZg09LsR+nnAeuBm4PKq2pLkwiQrumrrgduTbAU2AG+qqtur6n56UzufT3Ijvamiv5yJjkiSJpeqsdPzwzUyMlKjo6PDbsaslYSZ/j87FNeQNL2SbKqqkcnq+Y1cSWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGzBt2AzR1SWb0/AsWLJjR80sanoFG+klOS3JLkm1Jzj9AnTOTbE2yJcnaMfseleS7ST40HY1uWVVNaTmYY3bv3j3kXkqaKZOO9JMcCVwEnArsADYmWVdVW/vqLAPeAjy3qvYkecyY07wT+OL0NVuSdDAGGemfAmyrqu1VdS9wGXDGmDqvBi6qqj0AVfXD/TuSPBP4ZeDq6WmyJOlgDRL6xwC39W3v6Mr6nQicmOTaJNcnOQ0gyRHAe4E3TUdjJUkPzSA3cse7a1jjnGcZ8CLgWODLSX4F+G3gs1V120Q3H5OcC5wLcNxxxw3QJEnSwRgk9HcAS/q2jwV2jlPn+qraB3wryS30XgSeDTw/yWuBo4D5SfZW1QNuBlfVxcDFACMjI2NfUCRJ02SQ6Z2NwLIkJySZD6wE1o2pcyXwYoAki+hN92yvqtVVdVxVLQX+APjI2MCXJB06k4Z+Vd0HnAesB24GLq+qLUkuTLKiq7YeuD3JVmAD8Kaqun2mGi1JOjjZ/1nu2WJkZKRGR0eH3YzDRhJm2/+xpOmXZFNVjUxWzz/DIEkNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMG+blEzQGT/AbxuOX+nX2pPYb+YcIAlzQIp3ckqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDcls+1JPkl3At4fdjsPIIuBHw26EdAA+P6fP8VW1eLJKsy70Nb2SjFbVyLDbIY3H5+eh5/SOJDXE0Jekhhj6h7+Lh90AaQI+Pw8x5/QlqSGO9CWpIYb+LJJkSZJvJVnYbS/oto9PsizJ3ya5NcmmJBuSvKCrd3aSXUluSLIlyRVJfnEa23Vykt+crvNpbkuydxrO8fgkV0yw/+gkrx20vgZn6M8iVXUb8D+Ad3dF76Y35/kD4DPAxVX1xKp6JvA64Al9h3+8qk6uqpOAe4GzprFpJwOGvqZNVe2sqt+aoMrRwGunUF8DMvRnn/cBz0ry+8DzgPcCq4Hrqmrd/kpVdVNVXTL24CTzgH8G7Om2j0/y+SSbu3+Pm6T83yS5KcnXk3wpyXzgQuCs7p3EdL6Y6DAxwfPpiUmuT7IxyYX73yUkWZrkpm79pCRf655fm5MsozfgeWJX9p4x9Y9M8qdJbuzqv25Y/Z6Tqsplli3Ay4ECTu22/wz4vQnqnw3sAm6g967gy8CR3b5PA2u69VcBV05SfiNwTLd+dN/5PzTsx8VldizA3nHKDvR8+ltgVbf+mv3HAkuBm7r1DwKru/X5wC/07x+n/u8C/wuY120vHPZjMpcWR/qz028A3wN+ZbydST7VjcY/2Vf88ao6GXgsveB+U1f+bGBtt/5Reu8eJiq/FrgkyauBI6ehL2rDRM+zT3Tra8ce1LkO+MMkb6b3pwTunuRaLwX+oqruA6iq3Qfd6gYZ+rNMkpOBU4FnAW9I8jhgC/Cr++tU1Svojb4Xjj2+ekOfTwMvOMAlDvQZ3eqOfw3wVmAJcEOSXzqojqh1A38WvKrWAiuAu4H1SV4yySGZyvn1QIb+LJIk9G7k/n5VfQd4D/Cn9EZIz02yoq/6RJ/OeR5wa7f+98DKbn018JWJypM8saq+WlVvo/eHsJYAPwYe+RC6psPfgZ5n1wP/ultfOfYggCRPALZX1QeAdcDTmPg5dzXwmu7+Ffs/7aYBDXt+yeXnC3AuvWma/dtHApuAFwL/HPgssJ3e2+GrgZd29c7m53P6m7t6j+n2LQW+0JV/HjhukvJP0pseugl4P71R1UJgY3f+s4b9OLkM/Xn6U2BH3/LGCZ5Py4CvAl8D3g58tytfys/n6N9C793sDcD/ppujpzfYuYne4Ke//jx697m2Al8Hzhv2YzKXFr+RK2nGdN8XubuqKslKejd1zxh2u1o2b9gNkHRYeybwoW7q8g56n+zREDnSl6SGeCNXkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNeT/A+Oee9+D0QzYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "results = [opt.cv_results_['mean_test_score'], opt_logistic.cv_results_['mean_test_score']]\n",
    "names = ['XGBoost','Logistic']\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Code to load model later...\\n \\n# load the model from disk\\nloaded_model = pickle.load(open(filename, 'rb'))\\n\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code here to pickle best model, so that it can be transfered to Flask + HTML\n",
    "\n",
    "# save the model to disk; move this into the flask app\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "\n",
    "'''\n",
    "# Code to load model later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to predict regex class for\n",
    "a = 'a is the original sentence, b is the replacement sentence!'\n",
    "b = 'a is the original sentence b is the replacement sentence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to predict regex class for\n",
    "a = 'blah blah1 blah1114324'\n",
    "b = 'blah blah blah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to predict regex class for\n",
    "a = '4324£ ⇐'\n",
    "b = '4324'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to predict regex class for\n",
    "a = \"_r!e/g'e%x\"\n",
    "b = \"regex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to predict regex class for\n",
    "a = \"Sarah Connor 518-555-2394\"\n",
    "b = \"518-555-2394\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to predict regex class for\n",
    "a = \"Sarah Connor 518-555-2394\"\n",
    "b = \"Sarah Connor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because some of my functions from earlier need columns not raw strings:\n",
    "user_inputs = {'sentence': [a], 'end': [b]}\n",
    "user_inputs = pd.DataFrame(user_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Data Transformation\n",
    "Transform the new input data to fit the model input structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in character type counts features\n",
    "\n",
    "a_counts = charCounts(user_inputs['sentence'], 'start_n_')\n",
    "b_counts = charCounts(user_inputs['end'], 'end_n_')\n",
    "\n",
    "input_type_counts = pd.concat([user_inputs, a_counts, b_counts], axis= 1)\n",
    "\n",
    "#string ends feature:\n",
    "string_ends = endChecks(user_inputs, 'sentence','end', regex = False)\n",
    "\n",
    "input_features_combo = pd.merge(input_type_counts, string_ends, on=\"sentence\")\n",
    "\n",
    "X_new = input_features_combo.drop(['sentence','regex','end'], axis=1)\n",
    "\n",
    "#list(input_features_combo.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a function:\n",
    "def cleanInput(a, b):\n",
    "    \"\"\"\n",
    "    Function to perform feature transformation & engineering \n",
    "\n",
    "    @param a: uncleaned sentence\n",
    "    @param b: desired output sentence \n",
    "\n",
    "    @return: feature transformed data\n",
    "    \"\"\"\n",
    "    user_inputs = {'sentence': [a], 'end': [b]}\n",
    "    user_inputs = pd.DataFrame(user_inputs)\n",
    "\n",
    "    #add in character type counts features\n",
    "\n",
    "    a_counts = charCounts(user_inputs['sentence'], 'start_n_')\n",
    "    b_counts = charCounts(user_inputs['end'], 'end_n_')\n",
    "\n",
    "    input_type_counts = pd.concat([user_inputs, a_counts, b_counts], axis= 1)\n",
    "\n",
    "    #string ends feature:\n",
    "    string_ends = endChecks(user_inputs, 'sentence','end', regex = False)\n",
    "\n",
    "    input_features_combo = pd.merge(input_type_counts, string_ends, on=\"sentence\")\n",
    "\n",
    "    X_new = input_features_combo.drop(['sentence','regex','end'], axis=1).values\n",
    "\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2., 11., 10.,  9.,  2.,  2.,  3.,  0., 11.,  0.,  9.,  2.,  1.,\n",
       "         2.,  1.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = cleanInput(a,b)\n",
    "\n",
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Predict Class\n",
    "TODO: For multiple inputs, find median/average highest scored class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now input into the model to predict the class\n",
    "predicted_y = clf.predict(X = X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['^.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Match that value back to the initial class\n",
    "[regex_dict.get(y) for y in predicted_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted probabilities of each class\n",
    "#https://datascience.stackexchange.com/questions/22762/understanding-predict-proba-from-multioutputclassifier\n",
    "clf.predict_proba(X_new)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        a: _r!e/g'e%x\n",
      "        b: regex\n",
      "predicted: r!e/g'e%x\n",
      "    using: ^.\n"
     ]
    }
   ],
   "source": [
    "r = re.compile([regex_dict.get(y) for y in predicted_y][0])\n",
    "print(\"        a:\", a)\n",
    "print(\"        b:\", b)\n",
    "print(\"predicted:\", re.sub(r,'',a))\n",
    "print(\"    using:\", [regex_dict.get(y) for y in predicted_y][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: _r!e/g'\n"
     ]
    }
   ],
   "source": [
    "print(\"predicted:\", re.sub(re.compile(r'...$'),'',a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 code for visualizations and explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DecisionTreeClassifier' object has no attribute 'estimators_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-300-5df152501cc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Extract single tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DecisionTreeClassifier' object has no attribute 'estimators_'"
     ]
    }
   ],
   "source": [
    "# Visualize the decision tree:\n",
    "# From https://towardsdatascience.com/how-to-visualize-a-decision-tree-from-a-random-forest-in-python-using-scikit-learn-38ad2d75f21c\n",
    "\n",
    "# Extract single tree\n",
    "estimator = clf.estimators_[5]\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = iris.feature_names,\n",
    "                class_names = iris.target_names,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping Ground for old code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-4ba380d5173c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstart_regexed_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mchartable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcharacterTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mstart_by_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_by_char\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchartable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   6209\u001b[0m         return concat(to_concat, ignore_index=ignore_index,\n\u001b[1;32m   6210\u001b[0m                       \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6211\u001b[0;31m                       sort=sort)\n\u001b[0m\u001b[1;32m   6212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6213\u001b[0m     def join(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                        copy=copy, sort=sort)\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m    422\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                 copy=self.copy)\n\u001b[0m\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   5416\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_uniform_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5417\u001b[0m             b = join_units[0].block.concat_same_type(\n\u001b[0;32m-> 5418\u001b[0;31m                 [ju.block for ju in join_units], placement=placement)\n\u001b[0m\u001b[1;32m   5419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5420\u001b[0m             b = make_block(\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconcat_same_type\u001b[0;34m(self, to_concat, placement)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \"\"\"\n\u001b[1;32m    367\u001b[0m         values = self._concatenator([blk.values for blk in to_concat],\n\u001b[0;32m--> 368\u001b[0;31m                                     axis=self.ndim - 1)\n\u001b[0m\u001b[1;32m    369\u001b[0m         return self.make_block_same_class(\n\u001b[1;32m    370\u001b[0m             values, placement=placement or slice(0, len(values), 1))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "break original sentence and replacement sentence columns into character counts/presence.\n",
    "'''\n",
    "\n",
    "def characterTable(ref_sentence, sentence, regex = None):\n",
    "    \"\"\"\n",
    "    Break up sentence by character into data frame\n",
    "    \n",
    "    @param ref_sentence: the original sentence, which is used as a reference. Not broken-up\n",
    "    @param sentence: the sentence to break up by character\n",
    "    @param: regex: the regex reference\n",
    "    \"\"\"\n",
    "    out = pd.DataFrame(data={\n",
    "        'sentence': ref_sentence,\n",
    "        'regex': regex,\n",
    "        'char': [i for i in sentence]\n",
    "    })\n",
    "    return out\n",
    "\n",
    "start_by_char = pd.DataFrame()\n",
    "\n",
    "for index, row in start_regexed_end.iterrows():\n",
    "    chartable = characterTable(row.sentence, row.sentence, row.regex)\n",
    "    start_by_char = start_by_char.append(chartable)\n",
    "\n",
    "\n",
    "end_by_char = pd.DataFrame()\n",
    "\n",
    "for index, row in start_regexed_end.iterrows():\n",
    "    chartable = characterTable(row.sentence, row.replacement, row.regex)\n",
    "    end_by_char = end_by_char.append(chartable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use dummies to transpose the character column into their own columns for each character.\n",
    "'''\n",
    "dummies_start = pd.get_dummies(start_by_char, prefix='char_start', columns=['char'])\n",
    "dummies_end = pd.get_dummies(end_by_char, prefix='char_end', columns=['char'])\n",
    "\n",
    "\n",
    "\n",
    "# Define the feature columns\n",
    "r = re.compile('^char\\_start\\_.*')\n",
    "char_start_cols = list(filter(r.match, dummies_start.columns))\n",
    "\n",
    "dummies_start = dummies_start.groupby(['sentence','regex'])[char_start_cols].sum().reset_index()#Now sum up the values\n",
    "\n",
    "r = re.compile('^char\\_end\\_.*')\n",
    "char_end_cols = list(filter(r.match, dummies_end.columns))\n",
    "\n",
    "dummies_end = dummies_end.groupby(['sentence','regex'])[char_end_cols].sum().reset_index()#Now sum up the values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>regex</th>\n",
       "      <th>char_end_</th>\n",
       "      <th>char_end_!</th>\n",
       "      <th>char_end_\"</th>\n",
       "      <th>char_end_#</th>\n",
       "      <th>char_end_$</th>\n",
       "      <th>char_end_%</th>\n",
       "      <th>char_end_&amp;</th>\n",
       "      <th>char_end_'</th>\n",
       "      <th>...</th>\n",
       "      <th>char_end_|</th>\n",
       "      <th>char_end_}</th>\n",
       "      <th>char_end_~</th>\n",
       "      <th>char_end_</th>\n",
       "      <th>char_end_¨</th>\n",
       "      <th>char_end_É</th>\n",
       "      <th>char_end_Ê</th>\n",
       "      <th>char_end_Ð</th>\n",
       "      <th>char_end_Ò</th>\n",
       "      <th>char_end_Õ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[0-9]</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[A-Z]</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[^A-Za-z0-9]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[a-z]</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>\\d+</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence         regex  \\\n",
       "0  (Aug 22,2011)Plant Status of Fukushima Daiichi...         [0-9]   \n",
       "1  (Aug 22,2011)Plant Status of Fukushima Daiichi...         [A-Z]   \n",
       "2  (Aug 22,2011)Plant Status of Fukushima Daiichi...  [^A-Za-z0-9]   \n",
       "3  (Aug 22,2011)Plant Status of Fukushima Daiichi...         [a-z]   \n",
       "4  (Aug 22,2011)Plant Status of Fukushima Daiichi...           \\d+   \n",
       "\n",
       "   char_end_   char_end_!  char_end_\"  char_end_#  char_end_$  char_end_%  \\\n",
       "0          17           0           0           2           0           0   \n",
       "1          17           0           0           2           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3          17           0           0           2           0           0   \n",
       "4          17           0           0           2           0           0   \n",
       "\n",
       "   char_end_&  char_end_'     ...      char_end_|  char_end_}  char_end_~  \\\n",
       "0           0           0     ...               0           1           0   \n",
       "1           0           0     ...               0           1           0   \n",
       "2           0           0     ...               0           0           0   \n",
       "3           0           0     ...               0           1           0   \n",
       "4           0           0     ...               0           1           0   \n",
       "\n",
       "   char_end_  char_end_¨  char_end_É  char_end_Ê  char_end_Ð  char_end_Ò  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   char_end_Õ  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies_end.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Combine two dummies tables with start sentence, end sentence and regex\n",
    "\n",
    "May need to rename some columns with strange characters\n",
    "'''\n",
    "\n",
    "# Want to combine the start_regexed_end table and the new dummies_start and dummies_end\n",
    "# Should combine dummies first?\n",
    "# For now keeping dummies table separate from full combo of data, \n",
    "# want to keep set of engineered features separate and combine later.\n",
    "\n",
    "dummies_all = pd.merge(dummies_start, dummies_end, on=[\"sentence\",\"regex\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence',\n",
       " 'regex',\n",
       " 'char_start_ ',\n",
       " 'char_start_!',\n",
       " 'char_start_\"',\n",
       " 'char_start_#',\n",
       " 'char_start_$',\n",
       " 'char_start_%',\n",
       " 'char_start_&',\n",
       " \"char_start_'\",\n",
       " 'char_start_(',\n",
       " 'char_start_)',\n",
       " 'char_start_*',\n",
       " 'char_start_+',\n",
       " 'char_start_,',\n",
       " 'char_start_-',\n",
       " 'char_start_.',\n",
       " 'char_start_/',\n",
       " 'char_start_0',\n",
       " 'char_start_1',\n",
       " 'char_start_2',\n",
       " 'char_start_3',\n",
       " 'char_start_4',\n",
       " 'char_start_5',\n",
       " 'char_start_6',\n",
       " 'char_start_7',\n",
       " 'char_start_8',\n",
       " 'char_start_9',\n",
       " 'char_start_:',\n",
       " 'char_start_;',\n",
       " 'char_start_left_carrot',\n",
       " 'char_start_=',\n",
       " 'char_start_>',\n",
       " 'char_start_?',\n",
       " 'char_start_@',\n",
       " 'char_start_A',\n",
       " 'char_start_B',\n",
       " 'char_start_C',\n",
       " 'char_start_D',\n",
       " 'char_start_E',\n",
       " 'char_start_F',\n",
       " 'char_start_G',\n",
       " 'char_start_H',\n",
       " 'char_start_I',\n",
       " 'char_start_J',\n",
       " 'char_start_K',\n",
       " 'char_start_L',\n",
       " 'char_start_M',\n",
       " 'char_start_N',\n",
       " 'char_start_O',\n",
       " 'char_start_P',\n",
       " 'char_start_Q',\n",
       " 'char_start_R',\n",
       " 'char_start_S',\n",
       " 'char_start_T',\n",
       " 'char_start_U',\n",
       " 'char_start_V',\n",
       " 'char_start_W',\n",
       " 'char_start_X',\n",
       " 'char_start_Y',\n",
       " 'char_start_Z',\n",
       " 'char_start_left_square_bracket',\n",
       " 'char_start_\\\\',\n",
       " 'char_start_right_square_bracket',\n",
       " 'char_start_^',\n",
       " 'char_start__',\n",
       " 'char_start_`',\n",
       " 'char_start_a',\n",
       " 'char_start_b',\n",
       " 'char_start_c',\n",
       " 'char_start_d',\n",
       " 'char_start_e',\n",
       " 'char_start_f',\n",
       " 'char_start_g',\n",
       " 'char_start_h',\n",
       " 'char_start_i',\n",
       " 'char_start_j',\n",
       " 'char_start_k',\n",
       " 'char_start_l',\n",
       " 'char_start_m',\n",
       " 'char_start_n',\n",
       " 'char_start_o',\n",
       " 'char_start_p',\n",
       " 'char_start_q',\n",
       " 'char_start_r',\n",
       " 'char_start_s',\n",
       " 'char_start_t',\n",
       " 'char_start_u',\n",
       " 'char_start_v',\n",
       " 'char_start_w',\n",
       " 'char_start_x',\n",
       " 'char_start_y',\n",
       " 'char_start_z',\n",
       " 'char_start_{',\n",
       " 'char_start_|',\n",
       " 'char_start_}',\n",
       " 'char_start_~',\n",
       " 'char_start_\\x95',\n",
       " 'char_start_¨',\n",
       " 'char_start_É',\n",
       " 'char_start_Ê',\n",
       " 'char_start_Ð',\n",
       " 'char_start_Ò',\n",
       " 'char_start_Õ',\n",
       " 'char_end_ ',\n",
       " 'char_end_!',\n",
       " 'char_end_\"',\n",
       " 'char_end_#',\n",
       " 'char_end_$',\n",
       " 'char_end_%',\n",
       " 'char_end_&',\n",
       " \"char_end_'\",\n",
       " 'char_end_(',\n",
       " 'char_end_)',\n",
       " 'char_end_*',\n",
       " 'char_end_+',\n",
       " 'char_end_,',\n",
       " 'char_end_-',\n",
       " 'char_end_.',\n",
       " 'char_end_/',\n",
       " 'char_end_0',\n",
       " 'char_end_1',\n",
       " 'char_end_2',\n",
       " 'char_end_3',\n",
       " 'char_end_4',\n",
       " 'char_end_5',\n",
       " 'char_end_6',\n",
       " 'char_end_7',\n",
       " 'char_end_8',\n",
       " 'char_end_9',\n",
       " 'char_end_:',\n",
       " 'char_end_;',\n",
       " 'char_end_left_carrot',\n",
       " 'char_end_=',\n",
       " 'char_end_>',\n",
       " 'char_end_?',\n",
       " 'char_end_@',\n",
       " 'char_end_A',\n",
       " 'char_end_B',\n",
       " 'char_end_C',\n",
       " 'char_end_D',\n",
       " 'char_end_E',\n",
       " 'char_end_F',\n",
       " 'char_end_G',\n",
       " 'char_end_H',\n",
       " 'char_end_I',\n",
       " 'char_end_J',\n",
       " 'char_end_K',\n",
       " 'char_end_L',\n",
       " 'char_end_M',\n",
       " 'char_end_N',\n",
       " 'char_end_O',\n",
       " 'char_end_P',\n",
       " 'char_end_Q',\n",
       " 'char_end_R',\n",
       " 'char_end_S',\n",
       " 'char_end_T',\n",
       " 'char_end_U',\n",
       " 'char_end_V',\n",
       " 'char_end_W',\n",
       " 'char_end_X',\n",
       " 'char_end_Y',\n",
       " 'char_end_Z',\n",
       " 'char_end_left_square_bracket',\n",
       " 'char_end_\\\\',\n",
       " 'char_end_right_square_bracket',\n",
       " 'char_end_^',\n",
       " 'char_end__',\n",
       " 'char_end_`',\n",
       " 'char_end_a',\n",
       " 'char_end_b',\n",
       " 'char_end_c',\n",
       " 'char_end_d',\n",
       " 'char_end_e',\n",
       " 'char_end_f',\n",
       " 'char_end_g',\n",
       " 'char_end_h',\n",
       " 'char_end_i',\n",
       " 'char_end_j',\n",
       " 'char_end_k',\n",
       " 'char_end_l',\n",
       " 'char_end_m',\n",
       " 'char_end_n',\n",
       " 'char_end_o',\n",
       " 'char_end_p',\n",
       " 'char_end_q',\n",
       " 'char_end_r',\n",
       " 'char_end_s',\n",
       " 'char_end_t',\n",
       " 'char_end_u',\n",
       " 'char_end_v',\n",
       " 'char_end_w',\n",
       " 'char_end_x',\n",
       " 'char_end_y',\n",
       " 'char_end_z',\n",
       " 'char_end_{',\n",
       " 'char_end_|',\n",
       " 'char_end_}',\n",
       " 'char_end_~',\n",
       " 'char_end_\\x95',\n",
       " 'char_end_¨',\n",
       " 'char_end_É',\n",
       " 'char_end_Ê',\n",
       " 'char_end_Ð',\n",
       " 'char_end_Ò',\n",
       " 'char_end_Õ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Because the algorithms don't like when there are feature names that contain [, ] or <, just rename them\n",
    "Jan 31- right now algorithm doesn't take any feature names at all.\n",
    "'''\n",
    "\n",
    "dummies = dummies_all.copy()\n",
    "\n",
    "# Pickle dummies column names for later use; move this into the flask app\n",
    "dummies_cols = dummies_all.columns\n",
    "pickle.dump(dummies_cols, open('dummies_cols.pickle', 'wb'))\n",
    "\n",
    "# rename offending columns\n",
    "dummies = dummies.rename(columns={\n",
    "    'char_start_[': 'char_start_left_square_bracket',\n",
    "    'char_start_]': 'char_start_right_square_bracket',\n",
    "    'char_start_<': 'char_start_left_carrot',\n",
    "    'char_end_[': 'char_end_left_square_bracket',\n",
    "    'char_end_]': 'char_end_right_square_bracket',\n",
    "    'char_end_<': 'char_end_left_carrot'})\n",
    "\n",
    "# Check it out:\n",
    "list(dummies.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD CODE FOR DUMMIES TABLE FROM USER INPUTS\n",
    "\n",
    "'''\n",
    "OLD- These features no longer work for the training set.\n",
    "Make dummies table for new inputs like I did with the training data\n",
    "'''\n",
    "a_start = characterTable(a,a)\n",
    "b_end = characterTable(a,b)\n",
    "\n",
    "'''\n",
    "Use dummies to transpose the character column into their own columns for each character.\n",
    "'''\n",
    "dummies_a = pd.get_dummies(a_start, prefix='char_start', columns=['char'])\n",
    "dummies_b = pd.get_dummies(b_end, prefix='char_end', columns=['char'])\n",
    "\n",
    "dummies_to_fit = dummies_to_fit.reindex(columns = dummies_cols, fill_value=0)\n",
    "\n",
    "# Define the feature columns\n",
    "r = re.compile('^char\\_start\\_.*')\n",
    "input_char_start_cols = list(filter(r.match, dummies_a.columns))\n",
    "\n",
    "input_dummies_start = dummies_a.groupby(['sentence'])[input_char_start_cols].sum().reset_index()#Now sum up the values\n",
    "\n",
    "r = re.compile('^char\\_end\\_.*')\n",
    "input_char_end_cols = list(filter(r.match, dummies_b.columns))\n",
    "\n",
    "input_dummies_end = dummies_b.groupby(['sentence'])[input_char_end_cols].sum().reset_index()#Now sum up the values\n",
    "\n",
    "input_dummies = pd.merge(input_dummies_start, input_dummies_end, on=\"sentence\")\n",
    "\n",
    "'''\n",
    "Reindex the dummies table to the old columns list so the # of columns will match.\n",
    "This will cause model/site to break? Seems to handle: ⇐\n",
    "If the inputs have characters the model was never trained on this will cause mismatches in the number of columns.\n",
    "'''\n",
    "dummies_to_fit = input_dummies.reindex(columns = dummies_cols, fill_value=0)\n",
    "\n",
    "# rename offending columns\n",
    "dummies_to_fit = dummies_to_fit.rename(columns={\n",
    "    'char_start_[': 'char_start_left_square_bracket',\n",
    "    'char_start_]': 'char_start_right_square_bracket',\n",
    "    'char_start_<': 'char_start_left_carrot',\n",
    "    'char_end_[': 'char_end_left_square_bracket',\n",
    "    'char_end_]': 'char_end_right_square_bracket',\n",
    "    'char_end_<': 'char_end_left_carrot'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# More features?\n",
    "# Character counts by type (number, alphabet, punct etc.)\n",
    "\n",
    "# This is really ugly, something I could do in R very easily:\n",
    "count = lambda l1, l2: len(list(filter(lambda c: c in l2, l1)))\n",
    "\n",
    "start_counts = start_regexed_end['sentence'].apply(\n",
    "    lambda s: pd.Series(\n",
    "        {'start_n_punct': count(s,set(string.punctuation)),\n",
    "         'start_n_letters': count(s,set(string.ascii_letters)),\n",
    "         'start_n_digits': count(s,set(string.digits)),\n",
    "         'start_n_lower': count(s,set(string.ascii_lowercase)),\n",
    "         'start_n_upper': count(s,set(string.ascii_uppercase)),\n",
    "         'start_n_whitespace': count(s,set(string.whitespace)),\n",
    "         'start_n_words': len(s.split())\n",
    "        }))\n",
    "\n",
    "end_counts = start_regexed_end['replacement'].apply(\n",
    "    lambda s: pd.Series(\n",
    "        {'end_n_punct': count(s,set(string.punctuation)),\n",
    "         'end_n_letters': count(s,set(string.ascii_letters)),\n",
    "         'end_n_digits': count(s,set(string.digits)),\n",
    "         'end_n_lower': count(s,set(string.ascii_lowercase)),\n",
    "         'end_n_upper': count(s,set(string.ascii_uppercase)),\n",
    "         'end_n_whitespace': count(s,set(string.whitespace)),\n",
    "         'end_n_words': len(s.split()),\n",
    "        }))\n",
    "\n",
    "type_counts = pd.concat([start_regexed_end, start_counts, end_counts], axis= 1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_regexed_end.sentence[0].split() # Good for words later\n",
    "start_regexed_end.sentence[0][0] #can index by character position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Format differences into dummy variables\n",
    "1. [x] Create dummy variables for each character in sentence\n",
    "2. [ ] Create a second dummy table that captures the number of deletions that occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor each sentence X regex combo:\\n1. find all the diffs, and then match the characters with dummies, and remove that amount from dummies\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "For each sentence X regex combo:\n",
    "1. find all the diffs, and then match the characters with dummies, and remove that amount from dummies\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Because the algorithms don't like when there are feature names that contain [, ] or <, just rename them\n",
    "'''\n",
    "\n",
    "dummies = dummies_original.copy()\n",
    "\n",
    "#Pickle dummies column names for later use; move this into the flask app\n",
    "dummies_cols = dummies_original.columns\n",
    "pickle.dump(dummies_cols, open('dummies_cols.pickle', 'wb'))\n",
    "\n",
    "dummies = dummies.rename(columns={'char_[': 'char_left_square_bracket', 'char_]': 'char_right_square_bracket',\n",
    "                       'char_<': 'char_left_carrot'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Because diffs causes multiple training instances, just drop 'diff' for now and then find the column sums\n",
    "\"\"\"\n",
    "dummies = dummies.drop(['diffs'], axis=1) #Drop columns\n",
    "\n",
    "#Define the feature columns\n",
    "r = re.compile('^char\\_.*')\n",
    "char_cols = list(filter(r.match, dummies.columns))\n",
    "\n",
    "dummies = dummies.groupby(['sentence','regex'])[char_cols].sum().reset_index()#Now sum up the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features capturing differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>regex</th>\n",
       "      <th>char</th>\n",
       "      <th>diffs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[-+]?[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE][-+]?...</td>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[-+]?[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE][-+]?...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[-+]?[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE][-+]?...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[-+]?[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE][-+]?...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[-+]?[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE][-+]?...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[ES]</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td></td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>#</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>:</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>{</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>\\b\\d+\\b</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>\\b\\d+\\b</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>\\b\\d+\\b</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>\\b\\d+\\b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>\\d+</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>\\d+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>\\d+</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(Aug 22,2011)Plant Status of Fukushima Daiichi...</td>\n",
       "      <td>\\d+</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>. Renewable Energy Consumption Tops Nuclear fo...</td>\n",
       "      <td>[ES]</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>. Renewable Energy Consumption Tops Nuclear fo...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>. Renewable Energy Consumption Tops Nuclear fo...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>. Renewable Energy Consumption Tops Nuclear fo...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>{</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>. Renewable Energy Consumption Tops Nuclear fo...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>. Will liberals now seek to eliminate dangerou...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>. Will liberals now seek to eliminate dangerou...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>. Will liberals now seek to eliminate dangerou...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>{</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>. Will liberals now seek to eliminate dangerou...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>:Hello Japan is a nuclear power plant crisis. ...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>{link} The 1940 Olympics, decreased rice consu...</td>\n",
       "      <td>\\b\\d+\\b</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>{link} The 1940 Olympics, decreased rice consu...</td>\n",
       "      <td>\\d+</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>{link} The 1940 Olympics, decreased rice consu...</td>\n",
       "      <td>\\d+</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>{link} The 1940 Olympics, decreased rice consu...</td>\n",
       "      <td>\\d+</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>{link} The 1940 Olympics, decreased rice consu...</td>\n",
       "      <td>\\d+</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>{link} What's happening @mention Fukushima nuc...</td>\n",
       "      <td>@</td>\n",
       "      <td>@</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>{link} What's happening @mention Fukushima nuc...</td>\n",
       "      <td>@\\S+</td>\n",
       "      <td>@</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>{link} What's happening @mention Fukushima nuc...</td>\n",
       "      <td>@\\S+</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>{link} What's happening @mention Fukushima nuc...</td>\n",
       "      <td>@\\S+</td>\n",
       "      <td>i</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>{link} What's happening @mention Fukushima nuc...</td>\n",
       "      <td>@\\S+</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>{link} What's happening @mention Fukushima nuc...</td>\n",
       "      <td>@\\S+</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>{link} What's happening @mention Fukushima nuc...</td>\n",
       "      <td>@\\S+</td>\n",
       "      <td>o</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>{link} What's happening @mention Fukushima nuc...</td>\n",
       "      <td>@\\S+</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>{link} What's happening @mention Fukushima nuc...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>{link} What's happening @mention Fukushima nuc...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>{</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>{link} What's happening @mention Fukushima nuc...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>{link} Would you rather have a few dozen wind ...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621</th>\n",
       "      <td>{link} Would you rather have a few dozen wind ...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>{link} Would you rather have a few dozen wind ...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>{</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>{link} Would you rather have a few dozen wind ...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>{link} YNN/Marist Poll: How New Yorkers feel a...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>{link} YNN/Marist Poll: How New Yorkers feel a...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>{link} YNN/Marist Poll: How New Yorkers feel a...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>:</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>{link} YNN/Marist Poll: How New Yorkers feel a...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>{</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628</th>\n",
       "      <td>{link} YNN/Marist Poll: How New Yorkers feel a...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2629</th>\n",
       "      <td>{link} health newspaper articles Complete reje...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2630</th>\n",
       "      <td>{link} health newspaper articles Complete reje...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>{link} health newspaper articles Complete reje...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>{link} health newspaper articles Complete reje...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>{</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>{link} health newspaper articles Complete reje...</td>\n",
       "      <td>[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]</td>\n",
       "      <td>}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2634 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0     (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "1     (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "2     (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "3     (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "4     (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "5     (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "6     (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "7     (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "8     (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "9     (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "10    (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "11    (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "12    (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "13    (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "14    (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "15    (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "16    (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "17    (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "18    (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "19    (Aug 22,2011)Plant Status of Fukushima Daiichi...   \n",
       "20    . Renewable Energy Consumption Tops Nuclear fo...   \n",
       "21    . Renewable Energy Consumption Tops Nuclear fo...   \n",
       "22    . Renewable Energy Consumption Tops Nuclear fo...   \n",
       "23    . Renewable Energy Consumption Tops Nuclear fo...   \n",
       "24    . Renewable Energy Consumption Tops Nuclear fo...   \n",
       "25    . Will liberals now seek to eliminate dangerou...   \n",
       "26    . Will liberals now seek to eliminate dangerou...   \n",
       "27    . Will liberals now seek to eliminate dangerou...   \n",
       "28    . Will liberals now seek to eliminate dangerou...   \n",
       "29    :Hello Japan is a nuclear power plant crisis. ...   \n",
       "...                                                 ...   \n",
       "2604  {link} The 1940 Olympics, decreased rice consu...   \n",
       "2605  {link} The 1940 Olympics, decreased rice consu...   \n",
       "2606  {link} The 1940 Olympics, decreased rice consu...   \n",
       "2607  {link} The 1940 Olympics, decreased rice consu...   \n",
       "2608  {link} The 1940 Olympics, decreased rice consu...   \n",
       "2609  {link} What's happening @mention Fukushima nuc...   \n",
       "2610  {link} What's happening @mention Fukushima nuc...   \n",
       "2611  {link} What's happening @mention Fukushima nuc...   \n",
       "2612  {link} What's happening @mention Fukushima nuc...   \n",
       "2613  {link} What's happening @mention Fukushima nuc...   \n",
       "2614  {link} What's happening @mention Fukushima nuc...   \n",
       "2615  {link} What's happening @mention Fukushima nuc...   \n",
       "2616  {link} What's happening @mention Fukushima nuc...   \n",
       "2617  {link} What's happening @mention Fukushima nuc...   \n",
       "2618  {link} What's happening @mention Fukushima nuc...   \n",
       "2619  {link} What's happening @mention Fukushima nuc...   \n",
       "2620  {link} Would you rather have a few dozen wind ...   \n",
       "2621  {link} Would you rather have a few dozen wind ...   \n",
       "2622  {link} Would you rather have a few dozen wind ...   \n",
       "2623  {link} Would you rather have a few dozen wind ...   \n",
       "2624  {link} YNN/Marist Poll: How New Yorkers feel a...   \n",
       "2625  {link} YNN/Marist Poll: How New Yorkers feel a...   \n",
       "2626  {link} YNN/Marist Poll: How New Yorkers feel a...   \n",
       "2627  {link} YNN/Marist Poll: How New Yorkers feel a...   \n",
       "2628  {link} YNN/Marist Poll: How New Yorkers feel a...   \n",
       "2629  {link} health newspaper articles Complete reje...   \n",
       "2630  {link} health newspaper articles Complete reje...   \n",
       "2631  {link} health newspaper articles Complete reje...   \n",
       "2632  {link} health newspaper articles Complete reje...   \n",
       "2633  {link} health newspaper articles Complete reje...   \n",
       "\n",
       "                                                  regex char  diffs  \n",
       "0     [-+]?[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE][-+]?...    ,      1  \n",
       "1     [-+]?[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE][-+]?...    0      3  \n",
       "2     [-+]?[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE][-+]?...    1      2  \n",
       "3     [-+]?[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE][-+]?...    2      5  \n",
       "4     [-+]?[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE][-+]?...    3      1  \n",
       "5                                                  [ES]    S      2  \n",
       "6                          [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]          17  \n",
       "7                          [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    #      2  \n",
       "8                          [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    .      1  \n",
       "9                          [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    :      1  \n",
       "10                         [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    {      1  \n",
       "11                         [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    }      1  \n",
       "12                                              \\b\\d+\\b    0      3  \n",
       "13                                              \\b\\d+\\b    1      2  \n",
       "14                                              \\b\\d+\\b    2      5  \n",
       "15                                              \\b\\d+\\b    3      1  \n",
       "16                                                  \\d+    0      3  \n",
       "17                                                  \\d+    1      2  \n",
       "18                                                  \\d+    2      5  \n",
       "19                                                  \\d+    3      1  \n",
       "20                                                 [ES]    E      1  \n",
       "21                         [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]          12  \n",
       "22                         [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    .      1  \n",
       "23                         [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    {      1  \n",
       "24                         [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    }      1  \n",
       "25                         [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]          14  \n",
       "26                         [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    .      1  \n",
       "27                         [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    {      1  \n",
       "28                         [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    }      1  \n",
       "29                         [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]           8  \n",
       "...                                                 ...  ...    ...  \n",
       "2604                                            \\b\\d+\\b    9      1  \n",
       "2605                                                \\d+    0      1  \n",
       "2606                                                \\d+    1      1  \n",
       "2607                                                \\d+    4      1  \n",
       "2608                                                \\d+    9      1  \n",
       "2609                                                  @    @      1  \n",
       "2610                                               @\\S+    @      1  \n",
       "2611                                               @\\S+    e      1  \n",
       "2612                                               @\\S+    i      1  \n",
       "2613                                               @\\S+    m      1  \n",
       "2614                                               @\\S+    n      2  \n",
       "2615                                               @\\S+    o      1  \n",
       "2616                                               @\\S+    t      1  \n",
       "2617                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]           7  \n",
       "2618                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    {      1  \n",
       "2619                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    }      1  \n",
       "2620                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]          20  \n",
       "2621                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    .      1  \n",
       "2622                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    {      1  \n",
       "2623                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    }      1  \n",
       "2624                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]          10  \n",
       "2625                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    /      1  \n",
       "2626                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    :      1  \n",
       "2627                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    {      1  \n",
       "2628                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    }      1  \n",
       "2629                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]          15  \n",
       "2630                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    -      1  \n",
       "2631                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    .      3  \n",
       "2632                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    {      1  \n",
       "2633                       [^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]    }      1  \n",
       "\n",
       "[2634 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dummies for the differences when they occur\n",
    "'''\n",
    "1. If diffs == '-', then create/find column with char\n",
    "'''\n",
    "sent.loc[sent.diffs=='-'].groupby(['sentence','regex','char'])['diffs'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figuring out shit for character type counting etc.\n",
    "\n",
    "'start_n_': count(s,set(string.)),\n",
    "\n",
    "def mo(input1):\n",
    "    return input1.count(\"!\")+2\n",
    "\n",
    "def mo2(input1):\n",
    "    return input1.count(\"!\") + 22\n",
    "\n",
    "\n",
    "aux = start_regexed_end['sentence'].apply(lambda x: pd.Series({'feature1':mo(x), 'feature2':mo2(x)}))\n",
    "\n",
    "\n",
    "modf = pd.concat([start_regexed_end, aux], axis= 1)\n",
    "modf.head()\n",
    "\n",
    "\n",
    "# make new df to store these features in\n",
    "\n",
    "counts = pd.DataFrame(columns = ['sentence','regex', # for indexing\n",
    "                                 'start_n_alphabet', # alphabetical characters\n",
    "                                 'end_n_alphabet',\n",
    "                                 'start_n_numeric', # numeric characters\n",
    "                                 'end_end_numeric',\n",
    "                                 'start_n_punct', # punctuations\n",
    "                                 'end_n_punct'])\n",
    "\n",
    "for index, row in start_regexed_end.iterrows():\n",
    "    \n",
    "    print(len([c for c in row.sentence if c.isdigit()])) # start numbers\n",
    "    print(len([c for c in row.replacement if c.isdigit()])) # end numbers\n",
    "\n",
    "    \n",
    "count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n",
    "count(s,set(string.punctuation))\n",
    "count(s,set(string.ascii_letters))\n",
    "count(s,set(string.digits))\n",
    "count(s,set(string.ascii_lowercase))\n",
    "count(s,set(string.ascii_uppercase))\n",
    "count(s,set(string.whitespace))\n",
    "\n",
    "\n",
    "\n",
    "# words split on whitespace?\n",
    "len(s.split())\n",
    "\n",
    "# count white space\n",
    "len(s) - len(s.strip())\n",
    "\n",
    "string.ascii_letters\n",
    "\n",
    "string.numbers\n",
    "\n",
    "s = 'abcd!!!'\n",
    "\n",
    "count(s,set(string.punctuation))       \n",
    "    \n",
    "import string\n",
    "a = \"I'm not gonna post my homework as question on OS again, I'm not gonna...\"\n",
    "\n",
    "count = lambda l1, l2: len(list(filter(lambda c: c in l2, l1)))\n",
    "\n",
    "a_chars =  count(a, string.ascii_letters)\n",
    "a_punct = count(a, string.punctuation)\n",
    "\n",
    "    \n",
    "    \n",
    "start_regexed_end.apply(lambda sentence: len([c for c in sentence if c.isdigit()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for index, row in start_regexed_end.iterrows():\n",
    "    print(len([c for c in row.sentence if c.isdigit()]))\n",
    "\n",
    "\n",
    "len([c for c in s if c.isdigit()])\n",
    "\n",
    "\n",
    "sum(c.isdigit() for c in s) \n",
    "\n",
    "# punctuations\n",
    "\n",
    "\n",
    "#start_regexed_end.sentence[0].split() # Good for words later\n",
    "start_regexed_end.sentence[0][0] #can index by character position\n",
    "\n",
    "len(start_regexed_end.sentence[0])\n",
    "\n",
    "[c for c in start_regexed_end.sentence[0] if c.isdigit()]\n",
    "\n",
    "\n",
    "len([c for c in start_regexed_end.sentence[10] if c.isdigit()])\n",
    "\n",
    "\n",
    "def characterTable(ref_sentence, sentence, regex = None):\n",
    "    \"\"\"\n",
    "    Break up sentence by character into data frame\n",
    "    \n",
    "    @param ref_sentence: the original sentence, which is used as a reference. Not broken-up\n",
    "    @param sentence: the sentence to break up by character\n",
    "    @param: regex: the regex reference\n",
    "    \"\"\"\n",
    "    out = pd.DataFrame(data={\n",
    "        'sentence': ref_sentence,\n",
    "        'regex': regex,\n",
    "        'char': [i for i in sentence]\n",
    "    })\n",
    "    return out\n",
    "\n",
    "start_by_char = pd.DataFrame()\n",
    "\n",
    "for index, row in start_regexed_end.iterrows():\n",
    "    chartable = characterTable(row.sentence, row.sentence, row.regex)\n",
    "    start_by_char = start_by_char.append(chartable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "OLD CELL!\n",
    "\n",
    "Cool, created this data frame with some dummy data! \n",
    "But we should create some actual features that might important, e.g., difference\n",
    "'''\n",
    "def calcDiffs(a,b, regex = None):\n",
    "    d = difflib.Differ()\n",
    "    diff = d.compare(a,b)\n",
    "    tmp = list(diff)\n",
    "    out = pd.DataFrame(data={\n",
    "        'sentence': a,\n",
    "        'regex': regex,\n",
    "        #'diffs': [i[0] for i in tmp],\n",
    "        'char': [i[2] for i in tmp]\n",
    "    })\n",
    "    \n",
    "    return out\n",
    "\n",
    "sent = pd.DataFrame()\n",
    "for index, row in dat.iterrows():\n",
    "    a = row.sentence\n",
    "    b = row.replacement\n",
    "    \n",
    "    out = calcDiffs(a,b,row.regex)\n",
    "    \n",
    "    sent = sent.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "'''\n",
    "Using the dummies table from the trained data set, reindex the new dummies to fit the same standard\n",
    "https://stackoverflow.com/questions/28465633/easy-way-to-apply-transformation-from-pandas-get-dummies-to-new-data\n",
    "'''\n",
    "dummies_to_fit = pd.get_dummies(out, columns=['char'])\n",
    "\n",
    "#dummies_to_fit = dummies_to_fit.reindex(columns = dummies_cols, fill_value=0)\n",
    "# need to reindex on new feature set\n",
    "\n",
    "#Rename the columns\n",
    "# need to check the order this happens\n",
    "dummies_to_fit = dummies_to_fit.rename(\n",
    "    columns={'char_[': 'char_left_square_bracket',\n",
    "             'char_]': 'char_right_square_bracket',\n",
    "             'char_<': 'char_left_carrot'})\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "X_new = dummies_to_fit.drop(['sentence', 'regex',], axis=1) #Remove everything but the dummy variables\n",
    "\n",
    "#For whatever reason it's creating a separate matrix for each one. Add them all together instead\n",
    "X_new = X_new.sum().values\n",
    "\n",
    "#Reshape data for single sample\n",
    "X_new = X_new.reshape(1, -1)\n",
    "\n",
    "#add in character type counts features\n",
    "\n",
    "a_counts = charCounts(user_inputs['start'], 'start_n_')\n",
    "b_counts = charCounts(user_inputs['end'], 'end_n_')\n",
    "\n",
    "input_type_counts = pd.concat([user_inputs, a_counts, b_counts], axis= 1)\n",
    "\n",
    "input_features_combo = pd.merge(input_type_counts, dummies_to_fit, on=\"sentence\")\n",
    "\n",
    "list(features_combo.columns.values)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
